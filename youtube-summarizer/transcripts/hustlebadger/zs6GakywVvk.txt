Right. So every conversation I have with people seems to start at the same basic problem. And the basic problem is somebody walks into the room usually from sales or CEO some major stakeholder or partner and says the magic words of can't we just can't we just do something? This has been exacerbated by AI because you know we see all the amazing things that people are doing all the time and there's a lot of hype and there's a lot of stories and the reaction to the words can't we just is always the same. The first reaction is I can't believe I'm hearing this again. The second reaction the one we can't really help though you start thinking because can't we just is fun. Can't We just is, you know, virgin space. It is. There are no problems in Can't We Just at least not yet. The stuff we're working on now, that's boring. I mean, it's interesting, but there are problems with it, and we know the problems and we're trying to deal with them. But the can't we just is a is a new space where things might be magic and just work. So even though we know better, even though we should know we should say no or not yet or let's be cautious and think about this a little bit, we can't help thinking about what happens next in the the can't we just? So we start thinking about things and we start thinking about can we actually do this? Is this idea something that can be done? We start think about how much effort is it? We think about is this more important than what we're already doing. What would we stop? What would we delay or not do? This is the thing that people forget to talk about a lot of the time. But, you know, it is something that we need to think about. We think about what else might this impact. Uh, you know, we start with can we just do something over here, but usually there are other systems. There are other things that are going to be impacted by this that we don't think about straight away. And finally, we think about hopefully how does this affect the strategy that we have in place, the strategy that we discussed a while ago that we all agreed on. That is the most important thing for us as an organization. This can't be just as opportunistic. It's just we can do this. It's just something. It's just 5 minutes. It's just an hour. It's just a day. We can do this and everything else, can't we? This implies something, though. This implies that we actually have a strategy in place and that it's well understood. So, we're absolutely going to talk about the AI conversation and the can't we just conversation and how to do it, but I want to spend a couple minutes talking about strategy first because it is really important and it underpins this second conversation. And you know, we have the strategy conversation all the time. Companies get up, they present a strategy, they've usually gone off to an offsite of some sort. If you're in a leadership team, you've been part of it. And then you come back and you talk to people and say, "This is the strategy. This is what we're trying to do over the next quarter, half year, year, three years, whatever it might be." And then there's usually somebody off to the side who asks a question and says, "I don't understand what you want to get to this number. You want to get to something, but how is this helping us make decisions along the way? How is this how can I use this on the day-to-day basis?" That annoying person, that's usually me, actually. uh because the strategy is often incomplete. Lots of companies think they have a strategy, but they don't actually have one. There's a good reason for that. It's because they don't know what a strategy is. And it's one of those words that we all think we can define, but we've had problems defining it in the past. Um my favorite definition of what are the components of a strategy comes from Richard Rumlt. He wrote the book Good Strategy, Bad Strategy. uh some people love this book, some people hate this book. I don't really care. I love this and I will have no opinions about the rest of the book. But uh what he says is I uh is that he calls the kernel what he calls the kernel of strategy has three elements in it. It's got a diagnosis, a guiding policy, and a coherent action. And if you're leaving any of those out, it's just not a strategy. That makes a lot of sense. It feels good. It's a strong definition. But there is a fundamental problem with it is in that the words diagnosis, guiding principle, and coherent action are things that can be very misinterpreted by people. They're open to to discussion and open to to different interpretations. So I want to dig deeper into this just briefly. So there's that diagnosis, guiding policy, and coherent action. Um, one of my friends, uh, Asaf mayor had a better way of putting it said these are actually questions. It's where are we? where are we going and how do we get there? That's a lot more concrete. That's a lot easier to understand and it gets everyone on the same page. And the problem is that not every company has these. And then they should, you know, if you can write a user story, you can write a strategy because these three elements go into every user story. Another way of looking at them is saying this is a fact, an ambition, and a hypothesis. Where are we now? That should be a fact. That's work that you can do and an analysis that you can have. The ambition, where are we going? Are we going someplace that's 5% better, 50% better, or 500% better? That's really important. Just saying we want to get better at something doesn't give you the the the information you need to make good decisions. And then the how are we going to get there? That hypothesis, we are here. We want to get to there. this is how we think we're going to work together to get there. That is incredibly important because otherwise it's open to interpretation by different teams or different members of the teams and you don't get people working coherently together. There's no coherent action in the organization on how to achieve it. And most of the problems I see in companies uh come from this this lack of understanding this lack of having all three of these bits. And Romel says this, you know, the basic mistake that organizations and leaders make is they begin to conflate having a strategy with having audacious goals or ambitious goals. So they say, we want to get to 10 million ARR, 500 million AR. We want to get to 20 new customers. We want to get uh some big number, some big revenue or customer number in in the next, you know, six months or a year. It is important to have that. It's critical to have that. But that is not all that there is. You need that other piece. So when I work with organizations a lot, I see this and I say, right, we have the ambition. It's incredibly important to have it, but we need to do something about it. So the diagnosis I do, I'm guilty. I'm a consultant. I work with uh companies about having better conversations, about setting up a better environment so that they can actually achieve what they want to achieve. Uh how did they how do we make their product team successful? How do we make the company successful? So, I've got a 2 by two because consultants and 2 by twos of course, right? Uh so, my 2 by two very very simple. It's designed to be used very very quickly with people. Um first is do you actually have a strategy? Is it intentional or unintentional? Are you being proactive or reactive with your strategy? So, if you set something out and said this is not only the ambition that we have, but this is how we intend to get there. And you'd be surprised at how many companies are not very intentional about it, that they change every time some new piece of information comes in. And that's not to say that change is bad. Change is fine. When you have new information and it changes fundamental assumptions about your strategy, you absolutely should change. But it needs to be deliberate. And the other side is you can't just have the strategy. You have to tell people about it. And there are lots of places where that strategy has not been well communicated. It's not well understood throughout the organization. And there can be reasons for this. You know, if there are times when you specifically can't communicate things because you're dealing with sensitive uh uh information, it's usually around uh M&A activity and mergers and things like that. That does happen, but that is a very specific exception. You want the strategy to be communicated. And what that does for you when you're intentional and communicated, it gives you a set of principles that allows aligned decisions to be made at the appropriate levels of the organization. That means your developer knows when it's their turn to make a decision and when it's the appropriate decision to make and when they need to ask you as the product person the question. Your designer knows when they should be making a decision and when they should be asking you or involving others. you know when you should be making a decision or asking others whether it's something too specific for you or something that is bigger than you have the remit or the information to understand when you have a welloiled well functioning organization people understand what decisions they should be making what they should be talking to other people about how to communicate and collaborate well and I have a whole separate talk about moving your organization from any of these other quadrants into this we're not going to do that today but This is important to set up the conversation that we're having about having better discussions about AI. So, let's go back to this can't we just because the can't we just discuss the the question implies something especially when with AI in the the mix these days it implies something new. It implies not can we just do this little thing. It's can we do anything? But with now with AI, we've got magic pixie fairy dust and you can just wave your wand and go she bibbidity bobby boo and there we'll have it. We'll have it tomorrow. We'll have it next week. It's easy because that's what the hype says. That's what every article says. If you've taken Ed's course, you know it's not that easy. Um there are lots of things you can do. There are lots of things you can do faster. There are lots of things you can explore. But you can't just make magic happen by waving a wand. It's not to say AI is bad. There are lots of really wonderful things that we can do with it and we are going to come to to that. But we need to have the appropriate discussion about it. Uh both at the product development team level but also at that seuite boardroom strategy level. So really what we're coming back to is that question of how do we have better conversations? And I have these kinds of conversations every month. I have uh two groups that I do this with. I've got one called products in the ether. I see a couple people from that here in the today. Uh it's just a bunch of product people talking about whatever is bothering them. Uh and then I do one with CPOS every month at cpo.social as well. That one is by invite only. Uh, and the way that we approach this, the the way that I'm going to talk about today, um, is specifically came out of a conversation I had last summer with some of the CPOS. And we were talking about this this can't we just problem, somebody walking in and saying, can't you just wave your magic wand and make this happen? And we came to you uh, up with the idea of applying a framework, a framework that we know pretty well uh, that you may have seen before. And if you've seen this word, but you've never heard it pronounced, by the way, it is pronounced Kvan. Why is it pronounced Kvan? Because it's Welsh. And that's all you need to know about why it's Knevan. It is KVan. Knevan is a a framework that was developed by this guy Dave Snowden. He's a grumpy looking fella. Uh and it is in theory fairly straightforward and simple. It kind of looks like a 2 by 2. It's clear, complicated, cha uh complex, and chaotic. It's got this other thing of disorder in the center that makes it not a 2 x two. Um, strangely it starts in the bottom right and goes counterclockwise in terms of complexity. But the the main use case for this is to look at systems and to uh understand the characteristics of systems. And that understanding is key to the kind of discussion you want to be having with people both at the technical product development level but also at that strategy level. It is a really simple framework when you strip things back for it. So that's what we're going to do. But people can take this as they can take anything and make it extremely complicated uh or hard to understand. I realize I shouldn't have used the word complicated when complicated is one of the domain names but it's too late now. um it can get a little overdone and this is the danger of of people getting very academic about some of these frameworks. So we're going to go very very simple. The way that I find uh in my practice is if I can discuss something if I can describe how to get started with something in about two to three minutes with an executive then it's useful. If it takes any longer than that, minds wander. People start uh to think about why are we trying to approach it in a different way. So it should be very clear language, very plain language and very very easy to introduce. So I'm going to do this in about four or five minutes. I can do it into a three. I just want to give you a little bit more more background. So I've made it into a 2 by 2. I got rid of disorder because for me disorder and chaotic pretty much the same thing. And there's not enough difference that it's worth keeping it as a separate domain. Clear on the bottom right. Uh that's well it's clear. It's very simple stuff. It's something that you know you can describe essentially on one side of an A4. It's a tick list. It's something that it's deterministic um easy to describe both uh what it where you starting, where you're ending, what the result looks like, what a good result looks like, and the steps to get there. complicated is basically the same thing just more of it. It's like a really tough Lego set. It's again it's deterministic. You have all the bits and capabilities to do it. You know all the steps. You can describe them really well. It may be fiddly and long, but it is if you follow all these steps, you will get from A to B. And there's lots of systems within organizations that work that way and lots of systems that for new product development that potentially work that way. Complex is where it gets a little more interesting for me. Uh complex is non-deterministic in in how you get from A to B. A decision made at A may have implications at point C and D and E. So it's a very very fiddly. It's a lot of times there's intuition involved in how you get from one place to another. You probably could describe it, but it's going to look like, you know, uh, you know, when the movies when you've got the conspiracy theorist or the uh the the cops and they've got that big board up on the wall behind them and there's red string going everywhere. Complex kind of looks like that. It looks nuts, but you can get there. It's just hard and it's not straightforward. There's Yeah. And there's some magic or intuition. There's some judgment involved in it. And finally, there's chaotic. Chaotic is you make something uh you turn a dial over here and you have no effect what no idea what effect it's going to have at any given point and in fact you turn the dial once and uh it does one thing and two minutes later you turn it again and it does something else entirely you just don't understand the system at all yet. So when somebody comes to you with a problem and says can't we just the first thing is well let's understand what it is you're asking about is this something that is a a clear system a complicated system a complex or a chaotic system because where this is going to go uh fundamentally changes the the the thinking about can't we just do this and even should we do this so let's talk about using it in practice and in fact I just started doing it so things that are clear when they fall into the clear state. Um there's that's lowhanging fruit. There's probably not much uh return on investment for things that are in the clear state, but they they're great for practice. They're great to try out new things. Things in the complicated state are are interesting. They're great candidates for straight through processing. You know, tough things that are take a lot of time and effort. uh repeatable processes that you can uh describe, you should absolutely automate them. In the past, they may have been really really hard to do and now using the tools that are available to us might be a lot simpler. Uh lot the the the investment in doing them may be very different than it was in the past. complex. Again, there's there's judgments involved, but there are probably clear clear and complicated subsystems within a complex system. So, there are things you can do, but you probably won't get straight through automation, straight through processing. You probably want a human in the loop most of the time, at least for now. You might get to a point where the relative risk of something is very low. and you get to a point of you've got 95 to 99% confidence that you can predict what a human will say because you've got enough information. They may not have been able to describe it but you know you see something enough times it's like a capture enough times of describing something you can use NL and other processes to reverse engineer what the logic is even if it's very difficult for us as humans to to describe. And then finally with chaotic you don't want to automate these things. because you don't understand the system well enough to try to do it. It's a fool's errand to do it. But what you are trying to do there is potentially using tools to find patterns within the chaos. So maybe it appears chaotic but isn't as chaotic and you have advanced analysis tools uh pattern recognition, pattern matching things uh that you can't see, but throwing enough processing at it helps you find those patterns. So that's nice in theory. The question is what do we do about this? How do we make this useful? And what I'm arguing is that this is the basis for having these better conversations with people. Um because you can take this information and I have a much more uh detailed version of this table with a lot more information on on my site. Um if you go to the URL at the bottom, uh there's also a QR code at the end, but so don't worry about it. You will get all this the slides and everything else. Um but I using this information of determining is this something that falls which domain it falls into there are some simple rules of which technologies are probably the best to use with that type of thing and when you're talking about things that are clear not uh that aren't that hard that things that you can describe very well you probably don't even need AI most of the time you can use simple API integrations you can use RPA you can use uh new workflow automation tools and things like that. Um, and yeah, I go through all of these different things, but this is a conversation. Once I've had this conversation, say, with sales and CEO and everyone else, then I can sit with my dev leads and talk about which domain based on which domain this falls in, where uh how we understand it, which technologies, which approaches might we want to use. And that fundamentally changes our questions, our our approach to how we would do it because we have to talk about do we have the capability to use these tools? Have we done this before? Do we have the tooling available to us? Do we you know do we have the expertise that we need? So we can use this kind of an approach and analysis both at the level of your stakeholders and partners but also your building partners on things. So again using in practice uh you have these conversations it's worth going into the different uh domains and talking about the potential ROI and then you can have the conversation with your stakeholders and partners about can we actually do this? How much might it cost? How long might it take? And what's the profit opportunity? What's the estimate? Now we're talking in business terms. Is this practical? It is no longer a conversation about magic pixie fairy dust. It is back in the realm of the things that we talk about at a strategic level, at a business operational level about uh where do we put things on a roadmap? How do we change prioritization? And then we can finally talk about should we do this? How does it impact the strategy that we have in place? And what will we stop or what what what will we delay? None of this is new. This is classic product management. This is classic relationship management and strategy. AI unfortunately makes things confusing because people don't fundamentally understand the technology or technologies around it. So we need to take that away. We need to abstract that layer and be able to have the right conversation with the right people. Then we can figure out what we need to do about it. So I'm going to wrap this up in just a minute. Um the takeaways from today very very simple and straightforward. Make sure you have the right information about a strategy. What is the diagnosis? What is the guiding policy? What is that coherent action and all that so that you can ground the conversation and have the right conversations with people ones that allow the organization to as my friend Monica Terska says allows the organization to make better decisions faster. Ultimately that is the job that we have. That is the what we're trying to do in organizations. We are there not to be delivery managers although that is part of the job. If you don't deliver anything it you know you ultimately aren't getting value but not solely delivery managers. We are there to make sure and facilitate better conversations in the organization so that better decisions are made so that we can commit our resources, our time, our energy, our money to things that are helping and not waste our time on things that aren't. So I promised QR code and link so you can have all the slides uh the articles that detail this a lot in a in a lot more with a lot more information. This is really more of an overview of the whole thing. Um, I spend a lot of time talking to people these days about this type of thing and trying to help them have better conversations and facilitate that. If it's something you want to talk about, just get in touch. I'd love to to talk more about it. But I'm just going to shout out Ed's course, the Hustle Badger Building with AI course. Uh, one more time. I haven't done the Agenta course, the building agents course yet. I need to to sign up for that one as well, Ed. But the, uh, build with AI cohort is absolutely fantastic. It gives you, if you haven't done it, gives you an incredible overview and expertise and forces you to to get involved and really understand what are the possibilities. How does this stuff work? It's very practical, very easy and well thought out and I still use it uh the lessons I learned from it all the time. So, thanks again. >> Thanks very much, Randy. Um, love that. If if if you have questions, please do um stick up your hand or or put them in the chat. Um, so we can all get round to them. I know I've I've got a question. Um, you talk through these four categories, the clear, complicated, complex, and chaotic. Do you do you have kind of like practical examples of things um where you've seen kind of teams thinking about like, hey, we want to do this thing. How do we actually think about which of these buckets it falls into? >> Um, sure. So, a lot of the stuff that I I work with is either confidential or it's really incredibly boring. Uh, and it's boring because companies a lot of times are thinking about optimization of things. So, it's talking about can we do this better? Can we do it faster? Um, an example that I like that's public though, um, and I'm forgetting the name of the company, I think it was in in in Colorado. It was a a car dealership last year, I believe, that implemented uh an LLM into the chatbot on their screen. And uh, somebody said broke the chatbot and convinced it to sell them a Chevy Tahoe or something like that for a dollar. A $50,000 truck for a dollar. Fortunately, it turned out not to be a legally binding contract. uh fortunately for the for the dealership, not for for the customer. Um but this is an interesting thing because you'd think, you know, a customer service chatbot is something that is fairly clear to implement. It solves a problem. Um but it opened up a whole new new web of things because it was not given restrictions about which types of problems it was allowed to have authority in and which things to do. So, I would put this into that complex area. This there are some having a negotiation about the actual sale and the price of a car is something where you want a human in the loop. You might be able to write rules down, but people are very clever uh and they can convince chatbots at this point in LLM to do things that they weren't originally intended to do. So maybe you could get to the point of negotiating a potential deal, but ensuring that the chatbot was not authorized to uh commit to anything and would always escalate that to a human to make an actual determination and finalize a negotiation. for example. Um there's you know the the other side of it is uh there are things like lots of things with medical technology where you know um what we're seeing right now is that human plus uh machine learning is much better at uh diagnosing certain scans MRIs and things like that. It can notice things and the two together work really really well. At some point maybe there will be enough evidence there will be enough uh information that uh humans will not be needed to do so much as to to think as critically about it. Um so it's going to be interesting. I don't know where that is. I I would want to set the bar for that incredibly high. But obviously mistakes are going to be made uh by humans. They'll be made being by machines. But we wanted to get the best of both on something like that. Yeah, super. I have other questions, but I also want to give other people a chance to jump in. >> And I'm sorry, I don't have the chat up in front of me, so if you're putting in the chat, I can't see, but I'll ask Ed to just uh nominate people. >> I I I will I will prioritize other people's questions over my own. Um I'll jump in with another one, though. And these four categories, do you do you see their definitions as almost, you know, um immutable like they are they're always going to have the same kinds of tasks are going to have the same fall into the same categories because they are deterministic or nondeterministic or do you think the kinds of things that fall into these categories will change over time? So as I don't know like models get more sophisticated actually some things that used to be complicated are now simple just because the technology that we've got to apply against them is more sophisticated. >> Yeah. So I don't think the categories will change. I think the technologies and the approach we use to solving those those domains will will change. Um so that the table that I've got feels right. Um I've worked with other people on it. We I've had people since check it. feels right right now, but it's going to be different in different environments and as technology changes, you know, there's lots of things uh right now. You probably could use AI to do lots of different things. Um, but sometimes it's overkill and you're spending way too much money. You could be spending god knows how many tokens on something that you could do with a simple API call, with RPA, with other with other approaches that are much much simpler to do. Um and there are things where the level of risk is going to be very different. One of the the things we did is in the the chaotic domain, we actually broke it down to say there are things that you want to do for internal uh um operational excellence and uh the other side for when you're doing external. So, I wouldn't want to put something in the chaotic domain um into production straight away, but I might want to build something quick and janky to do something like I used to do with a Figma prototype or uh paper prototype testing and things like that and get in front of people and get some some feedback and see what can I learn from it. Um but yeah, I think that the do the domain definitions might not change very much, but what goes in them and what qualifies them for what we can do with them is definitely going to evolve. >> Yeah, super. Thanks. Uh Allison, you've got a question. >> Uh yeah, thank you. Curious, um Randy, how you then take uh teams or leaders through the next steps then? So you have this information and how do you in an effort to keep things moving talk through prioritization and you know taking all this then into that consideration and getting that clear path forward. >> I'm going to answer you. I'm just going to walk away for one second because this TV that I'm looking at in this room I'm not used to this is was it says it's going to turn off in a moment. It might do. If it does I'm just going to move over to my laptop. So apologies about this. Um, so the the question is how do I what's the next step with this? Honestly, it's it's about taking making sure that um the executives in the room sometimes feel like they're going to be left behind because they don't understand certain aspects of the technology and so they say, "Can't we just?" And if you can take that conversation and bring it back to the level of things that they do understand where they're contributing and you can as the the intermediary between product uh between technology and business if you can ensure that you are bringing the right amount of information to the room and talking their language saying this is how much effort this is our expertise this is our level of competence you know like we usually use things like rice and other types of uh uh prioritization and there's a confidence thing in and there's an estimate and these multipliers, they're all crap. You know, we're making them all up. This is trying to give you a way of of having that conversation better. Uh I'm in Oxford right now. I took the train up from London today. I was reading uh Rich Mirinoff's new book on the on the way up. It's it's called um uh I forget the name of it, but it's that something about money stories. And the idea is how do you have a better conversation with people so that you can prioritize appropriately and saying is this a four figure, a five figure, a six figure, an 8 figure opportunity potentially? What is the potential opportunity? What is the risk? What is the capability? If you can boil it back down to that and give everybody confidence about that, then the whether you're using aentic or LLM or rag or this or that doesn't matter. You know, you don't really want your salespeople talking to you about whether you should be using Rails or React. Um, you don't want them talking to you about the specifics of AI either, but they will if they if you're not having a proper conversation with them about the opportunity space and why you would do things and why you would change the strategy. So really, it's about reframing the conversation in the first place and trying to give people a way very very quickly to understand what is it they're talking about in a way that they're comfortable with. Uh and giving everyone the competence that they can contribute at an appropriate level and they're not being left out or left behind. >> Thank you, Ly. >> I see your hand is up. Yeah. Hi guys. Thank you Randy. That was a a really useful presentation. Um I think in addition to your question Ed, for me it certainly feels hard to keep track of evolving technologies. Um and I was looking at your recommended technologies column. What do you think is the right level of knowledge that a product manager should have to ensure that people listen to you? Uh that's a great question. Uh the way I usually describe it is I need to have just enough knowledge to be appropriately dangerous with my development team. As in I should know when they're lying to me. I should know when they're fudging things around. Um but I don't have to know the details of everything. I need to know enough to be able to ask the right questions at times. Um, and that is I get that that's not a very specific answer, but it really depends on the space that you're in. I hate giving you depends answers, but it depends on the level of sophistication uh that the the people around you have, how much you're trying to do, where in the the the cycle, the maturity cycle you and the company are, uh, what space you're the you're operating in. Um, yeah, I I'm sorry. I feel like this is a wishy-washy answer, but the the I want to feel confident that I'm having a valuable conversation with my development team. And if they can't give me a solid answer, then I want to learn more. Um, if they can give me a solid answer and we've built a trust, then there's probably a lot that I can offload to them. >> Yeah, it makes total sense. You need to do the work to understand where people are coming from and uh their levels of expertise. Okay, thank you. >> Yeah, I mean a certain point I when I go to my mechanic, I have no idea how to fix my car. I can describe the basic problem and I can describe what I want to happen. And if the Ooh, the TV just went off. Um, can you still hear me? >> Yes, we can still hear you. >> Can you still see me? >> Yes, we can still see you. >> Okay, then I can't see you, but that doesn't matter. Um, yeah. Yeah. So, when I go to my mechanic, uh, if he tells me it's going to cost five grand, I have to make a decision of is this still important? Is this something I care about? Is this is my car worth that much to me? Uh, if he tells me if it's 50 bucks, I'm going to be or 50 pounds in in the UK, uh, I'm going to be delighted. But, you know, if he gives me a number in the middle, I have to ask a question. Do I really need this? Why is it that? Um, but I don't know the first thing about cars. So it's kind of feel I feel the same way about about any technology ultimately. And then I saw you had a cheat sheet on this. Did you want to answer that one a little bit? >> Yeah, we do. If people are looking for a quick kind of resource then um we do have a cheat sheet of uh common AI terms that is worth checking out. So I' I've stuck the link in in the chat. Um I I would also say you know you can ask LLMs this. They're really good at explaining these sorts of things and it's certainly one of the big benefits I found over the last year is just having a kind of constant like coach and someone who will patiently explain things to me. Um that said, you know, there are some concepts like MCPs which even speaking to LLMs took me, you know, several weeks, even months to really get my head around. And it wasn't until I actually kind of went and built some simple ones myself that um I understood them. So I think for a lot of these systems um if you are trying to really understand them then spinning up a kind of a very simple project where you get to use them whether that's in you know n or your favorite kind of five coded coding tool this does give you an understanding on a on a much deeper level um assuming you have the time and the inclination to do it. All right. Any other questions today? >> Well, Randy, um, let's just wrap up with me saying thanks once again for um, coming in and chatting to us. Yeah, great talk. Really, really valuable concept there to think about uh, prioritizing AI features. As I mentioned to everyone, um we will be sticking the recording of this on our YouTube and we'll send you um a quick link when that's up. So um if you want to share it with anyone or or kind of check out bits again, then then you can do. Um but thank you very much Randy for coming chat to us and hope to see you all soon. >> Thanks again for hosting it and thanks everyone for coming. It's been a joy. >> Bye.