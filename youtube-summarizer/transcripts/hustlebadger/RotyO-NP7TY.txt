Um so with that let me get going. So um quote here from Y cominator. We always remind founders not to lose sight that the most important tasks for early stage company are to write code and talk to users. And I think that's so important um because you being close to your customers, understanding what they want is it's like a core function not just when you're founding but at any uh stage of a business. Um apologies for my slide title there which I obviously forgot to update. This is nothing to do with software application architecture. Um so I just wanted to kind of like anchor that you know talking about like how important is to talk to users. Um, it's important on the product side, it's important on the marketing side, it's important on the sales side. You know, everything you're you're doing in a business is essentially figuring out what users want and then creating a a solution that they will pay for. If you can't do that, you don't have a business and you know, the only way to find out what customers want is to go and speak to them basically. So, we're going to talk about two types of research uh broadly. um generative uh user research and evaluative user research. So generative user research, this is where you are you're asking open questions, you're effectively trying to figure out what are the problems that you should be solving for your users. So you're asking open questions. You're understanding their their lives. You're understanding how they do things at the moment. You're understanding how they see the world, what concepts they have, like what problems they've got, their needs, and how much value they put on different problems and how much um they would spend to solve those problems. So that as a sort of it's often gets into the jobs to be done space um where you're really just trying to understand yeah the competitive set and what is your value proposition overall. Evaluative user research is then very much in the solution space. It's much more targeted or tactical. So here you usually testing for usability. So, you have a feature um you know, a a prototype or mockups or a uh a concept and you're looking to get feedback on it. Um and usually, as I said, that that's, you know, very much like tactical usability. Do people know how to navigate through this this prototype. Can they actually get done what they want to get done? Is it obvious or does it need more explanation or better better signposting, better design? Um both of these though you know even if you're doing research in a fairly informal manner then sit in a kind of a process of finding users so actually if I say to you well you got to go and speak to users great and you've on boarded that like you where do you find those users which users do you go and speak to so you always end up in this this process which um in a mature company will be fairly well defined um and in a startup might be done fairly informally But you'll still be doing it whether you recognize it or not. So I'm going to run through this because it's going to provide the structure then for the for the rest of the talk um rest of the talk my words here. So um firstly you've got your design phase where you are forming your hypothesis. So this is sort of like why are you even speaking to customers? What do you want to understand from them? And again you know we'll talk about this in a bit more detail. You can write this up as a kind of formal brief or you could just have in your mind as you like get on the call like actually what do you want to get out of this this chat. But it's it's really important to have that in mind so that you don't just have a kind of very broad nice chat which actually isn't very useful but you actually do ask questions that kind of get you the answers that you want. So once you've decided why you're going to speak to users um you need to go and find some people to speak to. This is the recruiting phase. So, how do you actually come up with a pool of users that you can then go and go and find some to to speak to? Once you've got your pool, you're usually going to select um some of those that you're going to speak to. Um this can kind of get you effectively you can do the screening or the filtering like in the recruitment phase and only recruit people who meet your screening criteria. Um, sometimes you'll recruit like a whole bunch of people and then depending on what questions you want to get answered, you'll then filter that pool of of user researchers. Um, and uh in the screening process before inviting them to to uh uh an interview, then you've actually got to find a time to to chat with them, right? So, you might be doing this remotely. I mean, generally, you'll be doing this remotely. So, you'll just need to book in a a call with them. You might be doing it in person. you need to get them into your office or need to go and see them. Um, in which case, yeah, you'll need to sort out the location or the logistics of it as well. But that I I I include this because this can often be sort of like quite a big barrier just speaking to more users is actually this whole process of recruiting, screening, scheduling that is sort of like the difficult bit and actually once you're into speaking to people then that's kind of like fairly um straightforward or you know you start getting value straight away fairly easily, right? that's you know everyone wants to speak to users but it's the sort of logistics involved in some of these earlier steps that can make that difficult to actually make happen and then obviously once you've spoken to people or a bunch of people they need to work out what it all means. So um there's some sort of synthesis or analysis phase where you actually process what you've heard across you know one interview multiple interviews and share that uh with the rest of the organization so you own all know what's doing and I'd say like with this sort of process um in traditional user research right you're typically going through each of these stages in order so you know you've got a user research and you say, "Great. This quarter we'd like to find out about purchasing behavior of our, you know, super engaged buyers. Great." And they'll go and commission um or put together a a study and recruit a bunch of people. And this whole process might take, you know, two or three months to go through. I've I've definitely seen that in not large companies where the user research teams because they want to go through everything very thoroughly are taking you know a couple of weeks at each of these steps. If you're a fan of Terresa Torres and continuous discovery habits, then what you're doing is you're still going through the same phases. Again, probably not as formal as you would be with, you know, traditional or ad hoc user research, but you're doing them all in parallel simultaneously. So, you're always recruiting users and kind of adding them to a a pool of uh users you've got available to reach out to. And then every week, every month, you are then screening, scheduling, and running interviews. So that every week, every day, you've got someone new to speak to. And then your design effectively comes um like right before the interview where you say, "Okay, today the questions we have are X because you know you're always going to have questions." And then you just speak to whoever you've got time booked with. So it's two different approaches, right? The continuous discovery is really really useful for having like a constant pulse and constant feedback on what you're doing and making sure that you get really fast feedback. Um and then the what I call the ad hoc feedback where you kind of or you discrete feedback where you go and kind like run this pipeline end to end once off that is great if you want to do a really deep well ststructured research into you know something in particular um but it can be a little bit long-winded for day-to-day development. So let's run through each of those those phases and I say like each of these phases can be more or less formal right. So on the on the kind of very formal kind of very structured side of things in the design phase, you might fill out a user research plan. Um and yeah, this is an example template we've got on Hustlebadger, right? Where you're, you know, it's probably a page long and you're going through saying like, right, okay, what's the objective here? Uh who's the owner? What stage are we at in the product development? Um who are the stakeholders involved? What's the context? you're kind of like getting that, you know, problem definition and some of those related things down on a piece of paper so that you know if you're going to be spending money recruiting people um you know that money is well spent. It's obvious what you're going to get um for spending that money of recruiting people of you know doing doing user tests for them. If you're doing this much more informally, much more like continuous discovery, then you might just be asking yourself again anytime before the interview starts like what is the core question we are trying to answer and um how therefore like what are the questions we want to ask to get that answer. So examples here um you know you you might have a a a research question is it which is oh you know we're starting up a food delivery app. What are the main things that users care about for that? Is is speed of delivery the main kind of differentiator for them or is it something else? You might have another core question which could be something like oh we've got a new onboarding flow. Is it intuitive? Can people get through it? Do we need to make any changes to it? So this first question about what do users care about that would be generative research problem space um the second one around the onboarding flow that's evaluative research that's about the solution and evaluating that. So this is the um yeah design phase. Why why are you even wanting to speak to user? What are what are you trying to get out of these particular conversations? Second stage then you know why you're speaking to people. Great. Go and find some people to speak to. Um generally this is done >> question Ed. >> Yeah sure. >> So you are combining the generative and evaluative in one. Do you advise doing that or is it just better to do the generative first because it's kind of open-ended and then do evaluate ones separately? So you can I I'm just talking about them to make a distinction between them. So the the recruiting process is going to look fairly similar for both of them. The actual interview is going to look quite different. Often you'll be doing more one than the other. Um but sometimes and I'd say particularly in startups and scaleups it's useful to blend both of them where even if you are doing you predominantly evaluative research you still ask some open-ended questions at the beginning or even if you you know you've got a you know you want to talk to them about jobs to be done or something fairly generative you still bounce a few concepts off them to kind of stress test what they've told you. Okay, thank you. >> Um, Mark, I can see your hand up as well. >> Hey, yeah. Um, I had a question around customer advisory boards. Um, I'm looking to set one up with a a venture that I'm working on at the moment. >> Um, yeah, I believe I got a, you know, a base of users, maybe five to 10 people who are quite passionate and get involved. I have set something similar up in the past, but it just frazzled out. Um, I'm just wondering if you have any tips or guidance from yourself or anyone in the group in terms of how I can like set that up so it doesn't just peter out after a couple of weeks. >> Yeah, and I mean generally when I've seen customer advisory boards, these are running on a fairly long-term basis. So five or 10 people's great. Um but you they are meeting maybe like once a quarter or once every 6 months and then the company running them is putting quite a lot of effort into making those worthwhile for the people to turn up. Um so I think it's important to pick you know participants who really care about your product. Um you know it's almost like one it's kind of like one of the limitations one of the benefits. So you get people who you know they spend their day like working in your tool if you're doing that kind of um SAS thing which I kind of assume assume you are. Um and then you know as well as asking them questions you want to be probably giving them a preview of the road map. You want to be like showcasing how you've incorporated their feedback from before so that they feel engaged and and kind of bought into the the process. Um I I probably wouldn't with that kind of number of people try and have a you know always on WhatsApp group or something where you know you're expecting them to be just like chatting away every day. That that might work if you've got you know a few hundred people in it. So, um, when I was working at Depot, we had a, uh, a Slack channel for our top sellers and that had about 300 people in and it was almost like, um, a kind of priority customer service line for our our best sellers, but that worked because we had dedicated community manager and 300 sellers in it and, you know, they knew each other in real life to certain degree. >> Um, so hope hope that helps. >> Yeah, that helps. Thank you. Um, yeah. So, this is a So, you know, if you're doing this on a B2B side, you only need to recruit a handful of people. You can do that as a direct outreach, send them an email. If you're doing this B TOC and you want to recruit these people at scale, then you're often going to do this either in your own product or through your own marketing channels. So, emails, banners on your website, pop-ups, you could be running um even social media ads um to recruit people or you're going to go to an agency and pay them to recruit people for you. Um this is an example email we we've actually ran uh earlier this year at Hustlebadger, how we were recruiting people. And you can see it's like it's fairly basic, right? You know, you're just being like fairly straightforward and saying like, "Hey, we'd love to chat with you." And what we're doing here is we're we're just funneling people into a survey where we can capture their their details, you know, details of the people who are interested. Um, so we've got their consent to reach out to them about research, but also we can ask them a few more questions which we then use in the screening phase uh which comes after this. So here you might want to think about you know some highlevel screening. You know are you reaching out to new users or existing users? Are you going to set give those people incentives? Is there a slightly different pitch for people who are paying or non-paying users? Right? So you can tailor this message um slightly depending on who you're reaching out to. But I would keep this as straightforward as possible. Basically, um I would test it with without incentives and see what response you get depending on what your product is. You know, very often you will need to offer some kind of incentive. And again, I I would just keep it as low as possible and increase it to whatever it needs to be. You know, if you are recruiting students, um then 10 20 of Amazon vouchers might might work fine. If you need to speak to, you know, consultant surgeons um for your, you know, because you're doing a more kind of proumer or B2B type of, uh, product, then you might need to offer them something much more. And that that might not be financial, right? That could be some kind of other incentive of come to our event, come to our dinner, come to, you know, we'll offer you this thing that's really cool if if you get involved. So um screening people then what you should end up with after you've you know again if you've done this on a B2B size you've recruited like a lot of people you should end up with a database you know you've sent them to or you're sending them to a a form like this where you are then capturing a bunch more details and that is creating some kind of database then that you can you can look at for B2B this might just be a subset of your your kind regular CRM where you kind of tag people who are happy to be involved in in a customer advisory board or or user research. So you can see here yeah our survey again this is a real survey that we've used. We start with a fairly basic you know what's your email address so we can reach out to people and are you happy to have a call? So, we've got that kind of um key information up front, but then after that, we're going to ask people some additional questions that allows us to um sense check or kind of, you know, decide whether they're going to be right for the questions that we want to ask them. So, that might be things like, you know, in HustleB badges case, you know, are they a paying customer or not? Um have they, you know, done one of our courses or not? Like, you know, which aspect of the product have they used? have they, you know, when did they sign up? So, we can look at, you know, people who've joined in the last 30 days. Um, you might look at things like, well, what is the company size? What is their experience level? So, you can then have a look at how much they match your ICP as well. So, ideal customer profile. Um, so these kinds of questions you just, you know, you you want to use a bit of judgment there how many questions you can fit into your your survey where people actually complete it but you get some useful data. Um, but then you you can fill that out. A something else you want to do if possible um you know is match this with product data or or sales data. So, we've done this quite crudely cuz we're a startup where we've just asked people for their email address and then we can match their email address to, you know, what we see in Stripe, what we see in um our on-site tracking, what we see in our newsletter engagement. So, we we can get some kind of behavioral metrics and um commercial metrics out of those other systems from that email address. Um, obviously that's better if you can, you know, if your systems allow you to give them a tracking pixel or somehow automatically connect users who respond to your survey through to internal services cuz then you can you can map just a bunch of other data that you want to um map to them. That's then really useful so that when you're speaking to people, you're not just kind of saying like, "Hey, how's it going? Tell me a bit about you." you've almost got like a full briefing there where you know that actually this is someone who spent you know Â£300 with you in the last 6 months. They joined you know a year ago. They've done you know they've engaged with these three um you know product features but not the you know the fourth and fifth one that you're talking about and you you've got this whole context about what they do before you even get into the conversation. So that's just like really really um valuable then for getting more time out of them. But the real purpose of this kind of phase then this screening phase is you probably decide you don't want to speak to everyone. Right? So if you're going to be testing the onboarding flow then you probably want to speak to people who have joined in the last month. Whereas if you want to test the sort of um I don't know the the day-to-day flows and you know the key value proposition you might speak to people who are using this um you know at least three times a day using your product three times a day. So you can kind of decide how you out of all this information you've got and this this kind of these customer profiles you've then enriched which ones are you going to filter for before you actually invite them to into a an interview. So once you've made that decision, right, you you've created your short list, then you're going to send uh out some invites and and probably set up some kind of of call. Um again, we we use Calendarly for this. Um you might use Calendarly, you know, Google Calendar now has a booking page where you can do this. there are other kind of very similar services but you really want to automate this um because it is such a time sync uh otherwise and it's really easy to automate as well you know if you have a um Zapia or relay or any of these workflow automation tools you can easily be saying like hey of all the users that signed up in the last you know every day uh pick you know x at random and send them that first email sort of saying like hey can we have your feedback back and then if they answer it just, you know, ping x number every week uh a calendar link to book in more numbers and then depending on how your calendar's getting booked up, you can kind of adjust how many people you're you're automatically sending um emails out to. So this um again the nice thing about Calendarly um is you can block out times in your calendar. So, the way I do this is always to set quite strict times where maybe once or twice a week I'll have like a 2 or three hour window where people can book their their interviews. And again, you know, you kind of trusting them to do that because maybe you've offered them an incentive or maybe they're just really enthusiastic to speak to you because they love your product. Um, but then you know you're going to have like you've got a section of time in your week where you're always going to be speaking to customers. You just keep that free and if no one books a time that's great. you got some focus time, you know, back and you can work on on something else. Um, you know, one thing I've seen work really well is, um, also kind of enforcing this for, you know, senior people in companies. So, at Carwow, certainly what they were doing a couple of uh, years ago was, you know, every member of the exec. So every kind of CXO had to have a certain number of hours blocked out in their calendar every month for customer interviews. And they would then have that time blocked. No one could put anything in it. And the user research team would then kind of effectively set up the user interviews so that um some of these calendarly invites then went to the execs diaries. So the execs then had a steady flow of customers they were speaking to and all of them were just really really close to the customers. They weren't getting their information via teams or via reports. They were speaking to real customers every every month. So I think there's some you know you don't have to think too hard about this where you can set up your processes that it's not just one or two people who are doing user interviews but you're making sure your whole organization is speaking to customers on a regular basis and you're really kind of infusing the whole organization with that that sense of like who are our customers? What do they want? Um, so once you've got that that time then booked in your calendar, then you're on to your your point when you're like, "Okay, we're actually going to speak to these people." And and again, I'm kind of I'm going to go through the differences here between generative and evaluative uh research here. And broadly, this is the same whether you're doing this in person or whether you're doing this um remotely, right? There there's not, you know, there's there's some kind of like minor tweaks there, but probably not worth going into. So for whether you're doing generative or evaluative, um just a few kind of like words on opening and closing uh the conversation. So opening, you know, you typically remind people, hey, we're not testing you. Um there are no right answers or wrong answers. Please think out loud. Um so we understand how you how you're thinking about things. You know, don't worry about mentioning even minor things. you know, we're really interested in the details. You know, often you'll say, you might say something like, oh, you know, I'm not working on this product, so don't worry about offending me. Or you might just say, you know, we want to hear your honest thoughts. I mean, you can depend see how you phrase it. And you can remind them that you're you're recording it, which you should be. Um, and if they're going to get a a reward or an incentive uh at the end, then you're going to go into the your interview, right? So you you don't really want to give them any context or very little context on the idea or the company because you want them to come to that cold. Uh right, you want them to be as as though you had they had just landed on the on the website or as though they'd just come across the concept. Um so then you do your interview and at the end of it once you finish asking them you can close out by asking them, hey, yeah, any final thoughts? Any questions we didn't cover but you think I should have? um obviously thank them obviously confirm you know you've got the right details to pay them or give them their rewards and if you are kind of looking for more people to speak to so I'd say either you're doing more like enterprise um SAS or you're very early stage startup and you you know you're finding it difficult to recruit people then I would ask them for one more person to speak to So not like hey some is there anyone else we can speak to be like could you recommend one person right now that we should also reach out to. The rationale for that is if you ask people for just one person to speak to you or the best person to speak to, that is just significantly less cognitive load um and easier for them to do than to ask them for a list of two or three people. So you'll almost always get one person more and sometimes you'll get a few more than that. So you can continue doing your user research. Whereas, if you ask people for recommendations, everyone will say like, "Oh, yeah, great. I'll I'll drop you an email with a few names and then hardly any of them will actually follow up." So, even though in theory you're getting like more than one name for every uh interview you're doing, actually um you kind of you have a declining number of people over time. So, that's opening and closing. Um a few general notes on this. Uh so people are really unreliable witnesses. Um you know we think kind of oh courtroom drama you know the witness is going to be the thing that you know the person that makes or breaks the case. Like people are really really bad at remembering what happened and and kind of saying how they're going to act. And a large part of what you're doing uh when you're doing user research is effectively mitigating against how bad humans are at telling you about how they're going to do things. So a few examples here rationale um yeah people don't accurately report why they did things in the past um why they like things or what they might do in the future. So often and yeah there's there's tons of like great uh innovative experiments like proving this you know a lot of the time if you ask people um yeah even how they've done things in the past they will kind of make up reasons rather than actually recall why they actually did it. So they kind of postrationalize their actions and particularly if you ask them what they will do in the future they'll sort of go like they'll just make something up on the spot. they'll just kind of flag it and it won't really bear any relation to what they would actually do in real life. Um, there's also pretty good research that people don't have the ability to recall cognitive processes like what did they remember? You know, what do they remember in the past? Uh how do they come up with ideas? How do they make decisions? These are like specific things that people are like very very bad uh at recalling. So you need to be careful around asking questions in in these areas. Um people are often extrapolate the answers. So if they remember what happened then they will often fill in gaps between the things that they remember clearly but they won't often know themselves or admit to you what they're kind of making up and what is kind of a real a real recollection or or data point and how people answer depends a huge amount on the context. So, who's asking the question? What seems plausible to them today, you know, and what are the broader social norms uh about the topic they're being asked or what do they think, you know, is an expected answer. So, how do you deal with all these problems? This this seems like talking to people would be a horrible idea, but it is still a good idea. Uh I promise. Um, and you can make the feedback you get from people much much stronger and much more useful by sticking to a few basic rules. So, in general, don't talk about your product. Like, talk about them and their problems. So, most people don't really care about your product. They certainly don't care about it as much as you do. um and they you know probably haven't really thought about it until they've got there in in the room like or you know on the call at that moment. So don't make this about the product and ask them you know how we should tweak this or do that or do they like this button like spend your time talking to them about what they're doing their life what problems they have what challenges they face what routines and habits they have and and what's going on in their world. Secondly, yeah, ask for specifics. So if you catch yourself using the words generally, typically might do, you know, what what would you generally like? These are all like massive red flags where you should correct yourself and you want to ask people about what they did on a specific and ideally recent occasion. So this is very similar to when you are interviewing people for jobs, right? Yes, you can give them, you know, case studies and ask them what they do in a situation, but some people are really great at kind of just flagging it and just making stuff up on the spot and very bad at um actually doing that. Whereas, if you ask people how they dealt with situations in the past and what they did in the past, you're going to get a lot more accuracy. um you're going to get a lot more detail and you're going to be able to kind of dig deeper and kind of double down on the areas where you want to kind of uh get into the details and get more granularity. Thirdly, stay as little as possible. So, it's very very tempting to you know explain the context and the product and why you design things cuz you've spent a lot of time doing this. You've got to remember like that that is not useful to you at all. You you are definitely not trying to sell people on these calls. You are really just trying to say as little as possible to get them to give you more information. So don't waste the time on the call with you talking. Like you want to shut up as quickly as possible. Get them talking and listen to them. And finally um you know neutral language. So, you want to be as careful as possible that whenever you're asking people what they think of something or um to do something that you ask that in as neutral language as possible. So, they shouldn't be able to tell from your the way that you ask them whether this is your product or a competing product or you know you think it's a great idea or you think it's a horrible idea. um you should just be like completely flat throughout. So you don't ask them to check the onboarding is smooth. Ask them to go for the onboarding. Let you know what they you know what what do you think that that kind of uh thing that that then translates into um evaluative generative research in slightly different ways. So in the generative research, I sort of think there are basically three things you want to learn in most of these conversations. Um, and you can obviously go deeper on all of these, but in generative research, you're almost always trying to understand like what are the problems your users have. So questions you might ask are how do you do, you know, X some task or tell me about the last time you did this? Walk me through the last time you did this. So you can see like very much you're trying to get that specific time in the past. Um you did something when when did you last buy a dress? When did you last go clothes shopping? Great. What did you buy? You know, who are you with? You know, you can ask all these little questions to make them really kind of get into the mindset of when they were there. And then you can say, okay, tell me about that day out when you went when you went shopping. Like where did you go first? What time did you leave? you know, when did you leave the house type of thing. You you want to get to that level of detail and get them really kind of like centered in the experience. You then want often want to talk about alternatives. So, what would they do if their current solution didn't exist? Like how else might they solve their problem? And you might also want to talk to them about how do different solutions or different alternatives um value you how do they see the value between them. So I think something to to kind of bear in mind is that everyone's already got a solution to every problem that they've got, right? You know, so it might not be the same type of solution that you're thinking. You're thinking they need a SAS and at the moment they're using like 10 interns, but they've got some kind of solution or the solution is like we just don't care about this cuz it's not a big enough problem. So you want to feel out what those alternatives are and you want to understand the kind of relative pros and cons of them. And thirdly, price. So it's super important I think for any product just to understand the value that people put on problems because it's very easy to find things that people find very annoying and are happy to kind of complain about endlessly but they will never ever pay for. Um, and you know, some things like, you know, meal planning is a great example of this. People hate meal planning. It's the bane of their lives and particularly once they got families, they will like hmare trying to figure out what to eat that night. How many paid meal planners are there? Like zero. No one makes any money from selling recipes or um, you know, meal planning apps online. it all is bundled into you know existing supermarket checkouts and then not used very much. Um so so questions you can ask then about you what are you currently spending on this problem? What's your budget to solve this problem? What's an acceptable price for this? Um you know you can get into your van westernf kind of pricing questions. Um if you want to get more more specific. Um, but understanding how much people would spend on this is is really important to understand that if you build something, there is value there for your customers. On the evaluative side, you're not asking these big open questions, right? Because you're not testing for user needs or user value. You're testing for usability of a solution. So generally you're going to be giving people a um you know a prototype or a staging site or something like this and you're going to be giving them a specific task and scenario and then just ask them to complete that task and there you you're not going to ask them any questions. You're just going to ask them to talk you through the process as they do it. So few examples here like you're working for Uber. You're redesigning the account creation process. You ask them to imagine that they're heading off on holiday and they want to book a taxi ahead of time to take them to the airport. So, you want them to download the the Uber app, set up an account, and book a car. Super simple. A couple more here. You know, you're working at Stripe. You want to test the uh how easy it is for people to process refunds. So, you tell them they work for NSMB and you want them to log in and give Fred Smith with this email address a refund. Great simple task for them to do. Notion, you're working at Notion. You're trying out new functionality to add permissions, roles, and responsibilities. Great. You tell them that they've got a new team member joining, and you want them to log in, invite that person, and then give them the same rights and access as you. Okay? So, it's these sorts of tasks then you're asking people to do. And you can give people multiple tasks. um you can introduce new information as you go through, right? But basically, you're saying like, "Hey, go and do this thing." And you're just watching people uh and seeing what goes on. In both these cases, then digging deeper is like the fundamental skill. Um because the more that you dig in, the better the information is going to be. And generally, if you if you just ask people to like, "Hey, what's your problem?" Great. What do you think of this? you know, they'll talk for a minute or two and that might be interesting, but it's going to be very very superficial and it's only by really isolating and digging into each of the details that you kind of find the the breakthrough insights that are going to change how you think about things. Um, some words or phrases to use this, like it can be super simple. You can just be like, go on, or you know, tell me more about this. Um or you can say things like hey you mentioned this thing even if it's sometime later you know can you expand on that can you give me more color um can you go through and explain that process you know blowby-blow um you know don't be afraid to kind of just tell them to go and and ask them you know it's the first of these two uh examples here these are questions so you don't even need to ask them a follow-up question you just be like hey can you say a bit more about that simple as The other thing I think is really worth mentioning is um non-verbal cues. So, particularly if you're doing the evaluative research, um you really want to be watching them closely. So, you want to be watching their face as well as what's going on on screen. And you'll be looking for things like they pause, they frown slightly, they go quiet and stop narrating what they're doing because they're thinking. um they start actually reading the text on the screen rather than just kind of clicking the obvious CTA. Um you can see where their cursor is and you know if it's kind of like dancing about the screen. All these little things that you notice are going to give you a bit more insight about how they're thinking, what they're doing. And when you see them kind of change their behavioral pattern, that's when you might jump in with a question and be like, "Oh, hey. Yeah, I can see you're pausing there. what what are you thinking? You know, you could just like prompt them so that they remember that you already asked them to be speaking out loud and telling you what they're what they're thinking. So, final step here and and final slides, analyzing the results. Great. You've done your interview. Hopefully, you've done like a whole bunch of interviews. What do you do next? these insights that you've got now um they're only going to be useful if you actually use them to inform your decisions going forwards um you know your product decisions your marketing decisions so on. So you want to get the results out you know from your mind from the transcript to the wider company as fast as possible and as comprehensively as possible. as a kind of few tips I' I'd say here. Um this is a research repository that built. So you can see it's a notion page. They got a whole bunch of different um you know research projects that they did and they've tagged them up you know in a number of different ways. Basically as many different ways as they can think of. What was the team that did it? What was the methodology? What platform was it on? What features did they look at? What product areas did it cover? you know, did they ask buyers or sellers when was it done? This is super super useful. You know, it takes a little bit of upfront setup. But once this is in place, it means that going forwards, if teams have research questions, they don't have to go and speak to new users all the time. They can go back to what was, you know, the research that's already been done and see if there's anything in there. And this ideally you want to have a summary that you've written from the transcripts, you know, from the interviews that you've done quickly after you've done them, but you also just want the the raw interview transcripts and footage. Um, couple of years ago, two, three years ago, of course, you kept the transcripts and you'd never ever go into them again. Just like hardly ever saw teams doing that. Now that you've got generative AI and you've got LLMs, your ability to like quickly search through large numbers of transcripts and for transcripts to be super super valuable is really really high because you can plug those into some kind of ragbot and you can then just query um you know that can be as simple as just having a Google drive, right, that you connect to chat GPT and then you say like, "Hey, out of these transcripts, can you see if anyone talked about this?" You then want to go and check the actual transcript, right? and see what people actually said and make sure the LLM isn't kind of over reporting or hallucinating. But I think this is a fundamental change in the value of that kind of raw raw transcripts going forwards. And I'd say the other thing is I you share your findings like really quickly and broadly. So, um, don't worry about doing like a massive kind of deck or or something super pro because generally there'll be like one or two insights that are super valuable and then a bunch of kind like vaguely interesting stuff and you just want to get that like super important stuff out to as many people as possible. So when you have an interview or when you finish like a week of interviews, I would say like email or Slack message like all the people that are going to care about it, as many people as possible with just those highlights. Takes them two seconds to read. You can then dump that straight into your um you know into your repository and your zone. Then you can add to it later if you do more more um questions. Um, super. So, just to wrap, how are we doing for time? Yeah, quick. I just mention these quickly and then I'll ask uh some of the uh questions. So, as I mentioned, like a few things we've got on on Hustlebadger if you want to dig deeper. We've got our product discovery course. So, this is a um self-paced on demand course that's part of our monthly subscription. Um but a ton of you know things around speaking to users in there. Um the research brief that I showed the kind of uh upfront the survey the question you know we've got like a bunch more questions like you know bank of 50 questions you can ask people. So like all these things just in more detail you'll find in in that course as well as uh a bunch of other stuff and we also have just um a couple of wiki articles on qualitative re user research um that are worth checking out as well. I'm going to dump some links in again in case you missed