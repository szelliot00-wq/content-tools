Um, hey everyone. I'm Ed. I'm one of the co-founders of Hustlebatcher. We teach people AI skills. We also teach people uh product management. So, we cover sort of building things building digital products um with with modern techniques. And we have a whole range of courses, templates, uh howto articles and playbooks uh on the website. I'll tell you a little bit about it later. So I want to talk to you about JGBT power skills. Um a few kind of housekeeping points. Um this is being recorded. We will send you a link to the recording. Um if you miss anything or if I mention things you want to check it out again, we could do that. It's a live call though, so please do drop your chat uh your questions in the chat and I'll do my best to answer them. Um I'm going to talk about chat GPT kind of power skills. Um what are the skills that I use regularly uh that I've seen other people using um very effectively and I most of these will be applicable regardless of which LLM you are using on a regular basis. They're not really chatg specific. Yeah, they will work just as well in Gemini or or Claude with with maybe a couple of exceptions. Um, so I've tried to group these into um what do you call it? I've tried to group them into kind of like sensible categories so there's a bit of structure and it's not just a long list of things. But effectively what I'm going to talk you through is a few different areas, a few different principles. I'm going to try and showcase like actually what that looks like in the chats because I think that makes it come come live. And if we have enough time at the end, I will also live demo how I would do something in in chat GPT in case that's that's useful. Um, so yeah, let's let's get on with it. So as I say like four kind of like big topics here. I'm going to talk through one after the other. So firstly, just some kind of general principles. Secondly, the importance of giving LLMs the best context and some ways of doing that in kind of efficient smart ways. Um then inputs outputs things like voice images that are quite interesting and then talking about repeat tasks. So planning things custom GPTs um those sorts of things uh as well. Um, so let's dive in. Principles. So I think someone said this to me, um, and it it kind it kind of resonated like I said a few few months back. Yeah. They're like, "Oh, the great thing about LMN's is that they know everything." And the worst thing about LLMs is they know nothing. Um, I was like, "Yeah, it's kind of true." Like LM are great because they've basically ingested all human knowledge or all human digital knowledge and can tell you kind of anything that you want, but they don't really know anything about what you want unless you tell them that, right? They don't, you know, unless you give them context, you know, they they don't know anything about you. And that kind of leads to some sort of interesting dynamics, which is If you ask them for an answer, they will give you something very beige. They will default to the sort of average of all inputs in in you know human knowledge and that's generally quite boring and not what you want. Um, but if you use them to sense check what you're doing, if you use them to challenge you, if you use them to critique things, you as a thought partner, then they're great because they have this encyclopedic knowledge and they can generally give you like quite good feedback or kind of like they can challenge you in ways that you might not have considered because you are but one individual and you can only have so much life experience and so many thoughts um at a time. So, a lot of this talk is going to be about how to use chat GBT as a sparring partner. Um, where you are not kind of just taking your brain off the hook, forgetting everything that you know and getting them to give you an answer, but you're actually using Chad GPT to to augment how you're thinking and to make you a better thinker, both faster and higher quality in terms of output. Um so starting point for this um is getting options. So usually one of the first things that I do when I'm having a conversation with Chad GPT is I will ask it for some options on a way forwards. So I won't say like hey can you tell me how to do X. I will say how what are the different approaches we might do to to go you know solve this problem or to tackle this this project and if I've got some ideas then I might kind of seed it with a couple of ideas as well just to give it some some additional context. So you can see here I've shared some of these are all real conversations that I'm going to share. Um obviously you don't have the full context so uh hopefully they're kind of you get the sense of them even if the details don't make sense. And I I'll give you like a little overview of each of these conversations um but hopefully not bore you with too many technical details here. I I was trying to figure out um how to migrate the Hustlebadger website um because every week our website would go down like too many people would come onto the website at the same time when we sent out our newsletter and I was like okay we need to fix this and I was trying to therefore migrate us onto a a different server platform called Cloudways. I'd never done that before. I'm not a developer, right? I hadn't done any any coding like this or or or anything like this technical. So, I thought I'd talk it through with chatbt though and just understand what the options were and what the approach was. So, if nothing else, if I still had to speak to a developer or a freelancer to help out, I I kind of was a bit more informed. So, this is exactly what I did is I sort of asked it for a few options. And as it explained the options, it it kind of told me, you can see like, well, why might you choose this way or that way? And that allows me then to sort of figure out more about, well, what are the trade-offs I need to consider? It allows me to be more opinionated and to give it uh yout better direction. So I use this kind of technique quite a lot and not just for technical things but you know sometimes if I am um you know prototyping things I will ask chatpt to come up with different brand directions. So I'll say okay like this is what the you know the the the prototype is going to do. um come up with three different brand directions and that will kind of allow it it will kind of like force it to come up with a few different angles of what I'm talking about and then my reaction to each of those brand directions gives uh chat GPT even more context about what we're trying to achieve, what I believe in and and it's it it it it's easier than for me trying to just think about it um without any context myself. It also makes sure if there are any sort of options I haven't considered myself then um you know chatp can of often like flush those out. So I kind of start with this one as a really good way of um getting going. Next one then is is creating a plan. So often once I've got uh some high level options or I've kind of got that kind of variation, I'll be like okay now I understand the problem space a little bit more and I've we've talked about the the the different trade-offs here. I'll pick a highle option and I'll ask chat GBT for a plan. Um, and what I want to do is is really I think chat GBT can give you very poor quality answers when you ask it to do something quite complicated, but that's not broken down into steps because it's then sort of effectively for every stage in your process that you've got to go through, it's going to make some assumptions and it's always going to you again assume the middle of the road answer, the most common answer because that is what it does, you know, failing um better context. So by understanding what are the steps I wanted to go through I teas up for later in the conversation like talking through each of those steps and giving it feedback at each um step of the process. So this is um this continues the kind of conversation that you saw on the previous slide where I said okay great I picked one of the options it gave me I said right so understanding how we're going to migrate between these servers what do I need to do um and or actually this is a slightly different one I was building a microser so another coding example I was building a microser I got some uh I got some options I picked one great um what are the steps we need to go through now for each of these. I didn't want chat to give me the answer at this point because it'd be way too much information for me. And by the time we got down to the bottom, I was like, does this make sense? Because maybe if I change things further up the process, that'll have knock-on effects. So, I'm just trying to understand the overall um steps we're going to go through. And this is effectively then my project plan for going forwards. Um, and you can see I I'm I'm like very deliberately telling it, hey, we're going to walk through this, you know, step by step going uh uh going forwards. So, having got to that stage, once you've got your high level plan of what you're doing, then you're in a position where you can walk through that plan step by step. And with chatgbt, you can you can walk through like really quite technical things or things you have very little experience on and you can generally get pretty good results because at each stage you're having that kind of conversation where you're you're thinking about what are the options, what are the trade-offs, you're giving it a bit more context if you need to and then you're making a decision about how to go forwards and you're then getting instructions from chapter GPT how to go forwards. Um, if you don't do that, then what's going to happen is at every stage the LLM is going to sort of diverge from what you want slightly and that is going to compound over a number of steps until it's like way off track from where you want it to be. So this sort of like keeping on a very tight rain and moving through things step by step is very effective for getting high quality answers on complex tasks. Um this example here, I was actually generating a um a workshop exercise for a workshop I was going to be teaching and I wanted to to generate a case study for a dating website and the case study was going to be um an issue tree and I found like generating the whole issue tree at once like you don't you don't need to know what a issue tree is for the purpose of this example like generating the whole issue tree at once was like absolute disaster. Um it super generic like didn't make any sense as soon as you read the details. All the kind of classic problems of LLMs. Um but when I said okay this issue tree is going to have three levels. We're going to talk through each of those levels in turn. Let's start with level one then we'll do level two then we'll do level three. And at each stage I gave it feedback. Then actually the quality of the result that we got in the end was way way higher. And that was then something that I was happy to take into the workshop and use and and everyone could understand. So when you combine all those things together, you're going to ask for options, you're going to figure out a high level plan, you're then going to walk through each of those steps one by one, then you end up working away which I call the the very unscientifically the ping pong method. So you are you're kind of going backwards and forwards between your LLM you know whether that's chat GBT cla whatever it is um and some other tool you maybe a specialist tool uh like you know terminal or cursor or you know coding tool could be you know a fairly general tool like you know Excel or or or a word document or or something like this you know in chat GPT that's where you're giving it context you're forming a plan you're kind of like understanding the trade-offs, um, getting the the, you know, the how-to guides, the specialist tools, then when you're actually you're doing the work, you're kind of writing things down, you're kind of fine-tuning it, making final edits yourself, but also if you're getting feedback from other people or from other systems, you know, this happens when you're coding, like when things go wrong, you're kind of gathering data that you can then put more context back into the the LLM uh, as you go forwards. Um, and so this this kind of technique for, you know, ping ponging back and forth between tools where one end of that that that ping-pong in a general I found hugely effective for almost everything I do dayto-day now um as a founder, trainer, you know, product manager um type of person, you know, working like knowledge work. So if those are the principles, hopefully that wasn't too abstract. Hopefully that was um kind of concrete enough for the examples to make sense. I'm going to talk a little bit about context. By the way, if any of this you're just like, I kind of get it, but could you give some more examples or could you explain it in this context? Please again like stop me, put something in the chat. Um cuz I want to make sure this this is kind of like coming across you brag practically enough for you to actually use this going forwards. Okay. Okay, so let's talk a little bit about context. So, as I already said, you know, like if you don't give LLM's context, it's a default to the mean. That makes them give very generic advice. It feels very beige. You're just like I mean, it's not wrong, but it's just like it's so bland. It's it's basically unusable. And the way around that is to give uh LLM's more context or not always more context, but the best possible context. um possible for the problem they need to solve. So sometimes this is called context engineering. Um one way I kind of like load context into LLMs really quickly is I will just ask it about the topic. You know I know what the topic is about but I will ask it about the topic to almost like get it thinking in those terms and that sort of seeds the following conversation then in the terms of the topic we're about to discuss. So, example here, um, my my mother runs a small nonprofit in the UK, the Music Box Society of Great Britain, and she wanted to rebuild the website. So, we I said I'd help her and I'd help her by kind of talking her through how to use Chat GBT. And so rather than explain to Chat GPT like what this nonprofit did and you know give it all that kind of information um myself, you know, spend ages typing it up or or kind of explaining. I just asked it like I gave it the link was like, "Hey, this is the link. What does this do?" And you see immediately it's going to go and look at that that link there and it's going to work out like, "Okay, this is what this thing does." Great. And then you can see I'm straight into my my options again. come up with three brand directions for this site. So that then gave us three options which we then gave feedback on. So this is just like way way faster than I say kind of like you know being like okay you know you are a branding consultant for a um small nonprofit and I want you to do this and we're talking about this like you can move much faster than that. Um, obviously if it makes mistakes then you're going to correct them as you go along. But again, easier for you to correct things that you see it's coming up with than just do everything uh from scratch. Okay. The next technique that I really use here in uh in giving LLM context uh I call context pulling. Um, so again, rather than me sort of telling the LLM everything that I think it should know, I will tell it almost the bare minimum and then I will ask it to what it needs to know. I'll say like, hey, you ask me questions and I will answer your questions. Um, and this I found is it's much faster. It's much lower kind of cognitive load for me. Um, and you can get the LLM to answer any questions it you don't know the answers to. Um, just by reflecting them back. So, example, I I often use this for AI prototyping. So, I'll say, "Hey, I want you to write a spec. Um, I've got an idea. I'm going to give you a little um, you know, blur, some some some random thoughts that I've kind of pulled together, completely unstructured. I want you to fill out the spec. But before you do that, I want you to ask me any questions you need to to yeah, have sufficient context, remove any ambiguity about what we're building. And I will then kind of give it my little my little thoughts. Usually I'm dictating that by voice and then I will let it ask me questions and I'll just answer them as I go along. Now, sometimes it might ask me a question where it's like, "Oh, well, you know, your tech stack, do you want to do this or that?" I'm like, "I don't care about tech stack." So again at that point I can then be like hey give me what would be the mainstream answer or I if I think it might be I'm like I don't really know but that sounds important again I can kind of go back to be like okay well what would be some common options here and what would be the pros and cons of each. So I can get it to act as an advisor and I can then sort of give it the the context it needs to answer that question for me. Um, and in this case, depending on exactly how you write the prompt, you know, you might have to at some point you just cut it off and be like, "Okay, this has been fun, but I think you've I've answered enough questions now. Um, write the spec um or let's move on." Or another way of having this conversation is to um effectively limit the number of questions it asks up front. So you say like, "Hey, I want you to write a spec. This is very broadly the idea. you can now ask me five questions to remove any ambiguity. Think really carefully about those five questions. Um and it will then fairly um you know well kind of like think about what are the most important questions it should ask you and kind of count its way through those through those questions. This I have to say is probably my favorite technique if I if I had to kind of recommend one technique that you use like they all kind of compound together as you'll see if I do the live demo. But but this is kind of my my number one favorite technique that I really recommend that you you do. Finally, um on on context, I'm going to mention this this kind of prompt format race. Um I have to say I generally don't do this most of the time. The only times I really use um race, and I'll talk about what this is, is when I'm putting together a prompt that I'm not going to be able to edit. So, if I'm building a workflow, if I'm building a custom GPT and I want a really detailed prompt that's going to work kind of first time every time, this is the format I think about. But generally, I find having a kind of more of a back and forth asking for options, um, context pulling is faster and more fun than thinking too hard about the prompt up front. So for those cases when you do need a really detailed prompt um to get going, race is the format I think about um which stands for role, action, context, example. So RO is where you tell the LLM like what is the role that it's going to do and you know how does it do that role in general? Does it have a personality um or a style uh of doing things? action is then where you tell it what you want it to do and you give it any constraints um or any effective the specification of how it's going to work. Context is then where you sort of um you know free flow tell it any additional context that you think might help it give you better answers um which isn't a kind of hard constraint um or direction that you put in the action section. And then I think really really important if you want to get good quality output um is giving it examples. So yeah, as with you know briefing teammates, like if you want really consistent feedback, yeah, give it give it an example. You give it a template to fill in. Um it's so much easier for it to understand what you want if you say, "Hey, I want you to do this thing and here are two examples or three examples than just kind of getting it to um uh you giving it a bunch of specifications and letting it figure out." And that is to the point that often I will you almost like generate the examples I in another chat and then stick them into the prompt. If this is something that you know if if I'm creating a prompt for a custom GPT for example which we'll talk about a little bit later then I will probably dummy up the examples and make sure that they work um so that I can include them in the prompt uh going forwards. So um and you might give it you know inputs and outputs in certain cases so it can see how it adapts the the behavior. I think this is something where particularly useful you know if you have got um spective use previous documents and you can give it um those documents as as knowledge it's really really powerful. Okay, so we've done principles, we've done context. Um, I'll pause there. Any any questions at this point? Anything didn't make sense, anything felt a little abstract or you want me to explore in more detail? >> Hey, Ed, can I ask a quick question for you? >> Yeah. Um it may be related to the principles or the context piece, but when you were saying you stop when you feel like something is getting too too detailed when you're doing the back and forth, what's sort of your judgment criteria to say this is enough. I can stop. Let's move forward. >> Yeah. Um I think it depends on the topic you're doing. So the example I often have is I'm I'm AI prototyping. I want to create like a you know mini website and so I will give it the prompt ask it to ask me questions and then when the questions feel you know boring or trivial um or there's lots of things I just haven't thought about and I don't really want to think about then that's kind of a signal if I get like two or three of those questions in a row I'll be like okay this is this now does not feel like a good use of my time. Um, so yeah, for for AI prototyping, that'll often be things like, oh, you know, text questions or it's asking you minutia about, you know, minute details about like, well, what about if you're a logged user or not logged in user or if you're you're on mobile or something. I'm just like, I feel like, you know, there are kind of patterns for this that you can figure it out. So, um, the the other thing is you you can be so direct with LLM, like you know, you don't have to have all the kind of lightness that you'd have if you were having this conversation with a human. So, I almost you remind myself I'm talking to a robot, a machine by being very rude and be like, "Okay, that's enough. You've asked your questions. Let's go." Um, which is particularly fun if you're um doing it in voice and you can kind of really lay into it. Um, cool. Any other questions before we move on? All right, super. Let's talk about inputs, outputs then. So, um, probably my second piece of advice um or second favorite piece of advice I would say uh here is using voice input. it it is just so powerful. Um you can see this conversation. So this is a continuation of the conversation uh with the with chat GPT um and my mother about her nonprofit and actually the two of us were sitting around the kitchen table at this point um and I was showing my mom what the what Chpt had come up with and she started telling me what she thought. I was like whoa whoa whoa whoa. I don't want to have to type in everything that you're telling me. So, I just clicked on the, you know, the record button, the dictation button, and let her tell me. Um, and that was and, you know, and I think maybe I then added on some some further thoughts at the end myself. It doesn't really matter who's speaking, right? This is really powerful for a few reasons like it's way faster than typing. It's like two or three times faster than typing into terms of like words per minute. But it LLMs are also like really good at um kind of processing unstructured thoughts, the stream of consciousness and working out what you actually mean because naturally when you talk things over, you say the same thing in different ways. And that's part of getting your own thoughts straight. That's part of communicating things to other people. And that helps kind of LLM's kind of narrow in on what you're saying. So when you're doing this, you may have noticed like certainly in in Chad GBT, it has these two buttons. It has the one on the right um advanced voice mode, which is somewhat interesting, somewhat fun, but it talks back to you. So that's great if I'm like having a chat in the kitchen whilst I'm, you know, prepping food or something. Um, but during my work, I don't want I don't want CHBT talking back to me because that is then like a very slow way. I can read much faster than I can listen to what it's saying. So, I want to talk at it cuz that's faster than typing, but I want to read what it says. So, I then use this button on the left where effectively it's just transcribing what I say. It then sticks it in the box. I hit send and then it writes um its response back. You can also use some more advanced techniques here where you say, "Hey, I'm going to tell you things. Um, don't respond to what I'm saying. Um, just, you know, log what I'm saying because I want you to transcribe it or I want you to kind of give me some thoughts later." And then you can give it a sort of um like a trigger word, you know, like don't say anything until I say pineapple. I might spend several minutes giving you, you know, feedback because then if you're out for a walk, you're kind of like walking along, you have a thought, you kind of say something, chat doesn't try and do anything then because you haven't said your trigger word. You walk a bit further. You have another thought, you say a bit more. Great. Um, and then you're like, "Oh, that's enough." Right? Trigger word, pineapple. Write that all up. And it will then have like then go and give you a response on everything that you said because the the context window for audio is is pretty long. it's like 30 minutes or something. Um, so you can kind of have give it thoughts where you're not saying anything for a lot of the time. Um, and you're just thinking things over while you're and and then at the end get it to give you uh feedback. So yeah, this is super powerful. Honestly, I think this is so powerful that over the next few years, we're going to see a huge decline in the number of open plan offices because there'll be more and more pressure for people to have space where they can talk to their computers um without disturbing the people next to them. And this is why you were seeing so many of these yeah little microphone symbols not just in chatpt and Gemini but in all kinds of products where they are using LLMs to process the input um because it's just it's so effective. I'm I don't think voice is going to completely replace like visual inputs um but I think it's going to be a significant additive impact. Okay, second tip here on inputs is um images. Um so yeah, basically like screenshots and photos are like amazingly good ways of giving uh LLM's context and they're really good at reading what's in screenshots and photos. So this is an example kind of fun example. I was think I was like oh you know I'm a big fan of graphic novels. I was like, I got a bunch of graphic novels, but a lot of them are kind of rubbish, and I only really want really good ones. So, I know I'll ask Chad GPT for some um for some examples. Again, I don't want to read out or give it a long list of the the the graphic novels that I like because that will take ages. So, what I'll do instead is I'll take a photo of my bookcase. It can then transcribe all the titles that I've already got. it know it will then know what my tastes are and then it can recommend ones that are similar but I don't already have. So just a kind of really efficient way then of of giving it um examples uh sorry giving it context. Another example of this, um, I was, uh, working on an API. Again, not technical, don't really know how to use APIs or didn't 6 months ago before I started getting Chat GBT to explain it to me. And I was trying to figure out how to call the Spotify API and I was getting into all sorts of problems um, because it was it was way over my head technically, honestly. And I solved it basically by, you know, I was getting feedback from um the the workflow tool I was using and it was throwing an error and I couldn't figure out what was wrong and I just screenshot what I was seeing and copy pasted it into chatbt and chatbt I didn't even tell it what tool I was using. Um chatt looked at the screen was like oh I see the problem. um this parameter in the API call that you're making has a typo. You're saying uh credentials and actually that shouldn't have an s on the end. It should just be credential. So this isn't like a screen full of text about APIs. It is spotting this one little typo which is one letter that is causing the API to fail. So it's just very very powerful at doing at kind of like spotting problems like this. Um, and so now again I I am just like when I'm doing this kind of ping pong thing, I'm very very regularly just screenshotting my entire screen or like you know big chunks of my screen and dumping it into chat TV and being like what's going on? And then maybe I need to give it a little bit more context, but that's way way faster than typing things out or doing anything else. So um I think this is hugely hugely uh big time saver. Um, on the other side, getting stuff out. Um, canvas is a is a really big, um, timesaver kind of getting things out. So, if you haven't seen it, this is kind of like a ability um, Chat GP has to stick things in an editable document without leaving the chat. Um, you can get that it to do that by, you know, it's one of the addin options in the in the search bar down here. Um, or you can just tell it verbally, you know, or in writing, you know, put that in a canvas for me. Um, this is really valuable because if you're getting it to generate significant amounts of text, if it's made, you know, one or two bullets in a, you know, two pages of text that you don't like, you don't want it to regenerate the whole two pages or you don't want it, you know, you probably just wanted to kind of like edit a couple of different things. So this allows you to either highlight individual, you know, words, lines, and you can see here, give it like direct feedback on those lines and just rewrite that bit and leave everything else the same. Or you can go in and you can make direct edits yourself. Um, and I I think you you should never think about you getting to actually to do everything to the last kind of like full stop as the fastest way. Like almost always the final edit I'm doing myself. So it's like really exactly what I want. it's exactly um you know in my style and that's just the fastest way of getting there right like at some point I'm like okay fine you've got done the kind of 0 to 80 that's been super helpful you've done that in like 2 minutes I'm going to spend you know 10 20 minutes now for doing that final polish to get it really exactly where I want it to be the other thing you can do here is you you'll see the little um actually looks like an upload sign but um here it's the output you say how do you how do you save it you can save these canvases as um DocX files, PDFs or in markdown. Um and that's just really helpful for being able to then, you know, dump that into other systems. Is that something you want to continue editing, stick it in a code editor, have it have it somewhere else. You know, different file formats are, you know, useful for different things. Okay, so that was inputs outputs. Um let's talk a little bit about um repeat tasks. Or actually, I see Zach's got a little comment or question about images. Uh, let me just read this through. So, Zach's saying, "I do the screenshot thing all the time. My issue has been that chatbt typically hasn't been able to reference the current UI for various programs I'm using. It tells me to do blank or go here and that's now not what I see. It takes forever to get us in the same position where it says, "Oh, that's because they changed the UI." Yeah. I mean, this is definitely a risk of the screenshot problem is that you know, particularly because chat GPT isn't always trained on the latest um documentation. So to have like the latest documentation, we'll have to search the internet and find it. Then it will often kind of be like, oh, you just need to click here and um that that isn't the answer. So I I know exactly what you're saying, Zach. The way that I get around that is often, you know, I'll see if it's right firstly and if it if it's wrong, I will then just be like saying, you know, challenging it a little bit, saying like, okay, are you sure this is right? Are you sure this is possible? Can you double check this? Um, are there any workarounds to this sort of thing? So, I'm just doing that kind of like sense check where I'm if I'm getting stuck, then um just quickly kind of trying to validate if if what it's is there. And I think that's that's true in a lot of cases. If you've got even the slightest doubt that chatbt is kind of like not giving you a straight answer or might kind of be um leading you astray, just ask it like are you sure because this seems wrong to me and like good chance it will then kind of correct itself if that's not strictly true or spend a little bit longer thinking about it. Okay, so talking about repeat tasks here and plans. Um custom GPTs. So custom GPTs are ways of effectively saving a prompt so that you can use it again. Um and so if you're doing something you if you're getting chat GPT to do exactly the same thing multiple times then creating your own custom GPT is a really effective um kind of uh hack and as well because what you'll find is over time you'll improve that prompt to make the output better and better. Um, and so this is where that that kind of race format for prompts comes into use where you want to go through the role, the action, the context examples. So you can see here I've got a few uh ones I use. So for example, this webinar um once we finished it, you know, I'll get the the transcript, I'll get the um the recording from this call tomorrow. Um, I'll then put the transcript into my YouTube notes custom GPT and you can see some of the out um some of the kind of prompt here and it will then convert that into my YouTube show notes. So when I upload the recording of this webinar to YouTube tomorrow or now if you're watching on YouTube um then um you know I don't have to spend 10 minutes rewriting the the show notes. I just get those automatically. Um, so that's super useful um, way of doing it and you can see I I use it for a few kind of social media things there as well. But you know, if you're creating PRs in a particular style, you're writing documents in a particular style, um, writing emails, any kind of repeat thing that you're using for, then creating a custom GPT is is super useful. There is a marketplace for these. I honestly I've never bothered to explore it because I really want to know what's going on behind the scenes and so I wouldn't trust anyone else's GPTs to do stuff for me. Um and I it just feels like it would take a long time to kind of sense check them to make sure they're actually doing what I wanted them to be doing. Um projects. So another thing you can do in uh chat GPT and these last two I'm not I'm not sure how useful they are for other uh LLMs but certainly I mean there are equivalents right so even if you're not creating your own custom GPT you could be saving your prompt somewhere you could just be saving it in a notion doc or you know a word doc somewhere and then editing it yourself and not quite the same but but fairly fast way of doing it so projects um you'll see that there's this little kind of projects um kind of section in chat GBT. This I kind of missed for ages cuz it was so so subtle. But in between your custom GBTs and all your chats, you're going to have um a bunch of folders. When you put in folders, it kind of groups a bunch of chats together. And you can also add files here for additional context. So you can see I've got a you know bunch of um conversations now around whenever I'm doing things, you know, coding things on the Hustle Badger site. I sync those all in one place so I don't have to reexplain what the technical strategy is or what the tech stack for Hustle Badger is um or you know who my my server provider is like that is all kind of context that it already has. So it's just a faster way of again giving it like the right amount of context so it can give you really good answers. Um so this is super useful for working on particular topics, working on particular projects. you know, you've got like a project for a feature you're working on. Um, or you if you've got big clients like working on an individual client and like what are they saying? Like all those sorts of things are kind of really useful to kind of stick together here. I said it's like adding files that again is like a real superpower where you can dump in other documentation, research, um, you know, customer feedback. There's so much you can put in there that will then give it um more knowledge and you you know you can also add in customer transcripts, calls transcripts, these sorts of things so that you can then ask questions about about um you know what's gone on in those calls. Okay, so that was um my tips broadly. Um if you I'm going to take take a moment to give you a little pitch about Hustlebadger right now. If you want to keep learning about AI stuff, then we have four courses now which are really great and I and I hugely recommend. Firstly, we've got a new course coming out next year called AI competency that's effectively taking all the skills that you've learned here um but helping you apply those into your day-to-day job. So if you're like LLM's too much, or if you've got teammates where you want to help them get up to speed really, really quickly, this is a four-week course to help you use chat GPT effectively dayto-day to increase your output and your quality of work. We have another course called Automate with AI. If you want to build a team of agents that is going to help you with productivity wins day-to-day, check out our automate with AI. We will build 12 agents over the course of four weeks um to help you with everyday things. Um, third of course this one's built with AI. This is like the kind of broad brush if you want to learn a bit of automations, a bit of AI prototyping, a bit of coding with AI. This will really just give you a like an amazing grounding in like what are the AI tools out there? How do you use each one? And again, like every week we're building things practically that you can actually use in your in your your day-to-day job. And finally, if you want to get better at building AI products themselves and you want to learn about building your own agents, deploying them, running evals on them, if that's something where you want to have like a live agent that you have built end to end, um, and you can put in your portfolio or showcase at your company, um, that is the course for you. Um, I see there's one question in the chat. I'm going to answer that and then I will take just five minutes to do a live demo in in chaptt. Um to Anton saying there's also one more input that I found really powerful. I often chair participate in meetings which various reasons I end up recording and then have transcribed. What I've started to gather is these transcriptions in a common area that I call knowledge area and then when working on that area use the whole thing as background. Yeah, absolutely. So, I think there's just huge value in recording calls at this point because those transcripts, whether they are um you know, meetings with colleagues, meetings with with clients, they're really really useful for giving LLM's context because again, they're so good at processing that. Um so, Anton, big thumbs up. Agree with that. Um completely as a way of um giving more context. Okay, so let's change sharing. I'm going to change something. Maybe I stop sharing and share something else. Okay, so this will be quite quick, but I just thought it'd be really useful for you to see how I might do something like plan a holiday um using ChattyPT. Um so we're going to imagine that maybe I want to go on holiday with my family next year. I've decided I want to do a city break, but I haven't really thought about it. Um and I'm going to get Chad GPT to help me with the process. Hey, so I want to plan a family holiday, so springtime next year. Um, I want to do a city break, but um, I haven't really got any thoughts beyond that. What would be the highle process for planning this? Um, I just want to come up with a high level process to begin with, and then we can talk through each step one by one so that you can help me figure out what we're going to do. Okay. So you can see there I'm using voice just to kind of give it some initial context. I'm just trying to get the the high level plan. Okay. It's going to come back with some plan. Define the constraints. Set the criteria. Show some cities. Pick a front runner. Shape the trip blah blah blah blah. Lock in the core bookings. Light structure. Practical prep. Yeah. Fine. That that sounds um great. So, I'm going to make up some details here um just to kind of give it some some further thoughts. By the way, one thing I would I should kind of highlight is LLM will always ask you a question at the end of their chat. That is not really them being helpful. That is an engagement um tactic used by OpenAI, used by Google to get you to stay in the conversation for longer. So, ignore the last question, whatever it is, and just tell it what you want to do. Um, I think it's a real dark pattern to be honest. I think it's awful. Okay, so um, yeah, let's talk through the constraints. So, budget range, I want to spend, uh, Â£2,000 in total. Um, I'm looking at the first weekend in April. I want to go for a long weekend, maybe 4 days, Friday through to Monday. It's going to be two adults uh, and an 8-year-old. um prefer trains if we can go on the Euro Star. Um but maybe we'd be open to flights if it's kind of somewhere really cool and I think we'd be willing to go for like two and a half hours. Let's see what comes out there. Okay, so again, we're just going to walk through step by step now. And again, I'm just ignoring this chat but talking in voice to get it to plan things out. I'll get it to obviously I could do this for every single step, but I'll try and mix up a little bit between the steps so that um you get some idea of how things are working. It's going to take a while over this one. Okay. Okay, so it's got all my constraints. This like calculations you got to be careful of, but this seems to roughly make sense. Set the criteria. Okay, one more question. Is is that meant to cover everything? Yeah, I want that to cover everything. Uh on the criteria, gosh, I haven't really thought about this. Um can you make some sensible suggestions? is based on what I've already told you. Okay? So, I'm just not going to ask the question about vibe or weather or or that sort of stuff. I'm I mean, this is somewhat unreasonable, right? Okay, here's the first part. So, I can review this and I can just uh say, check this makes sense. Um, weather and seasonal fit, mild enough to walk around. Yeah, that sounds good. Easy public transport. Walkable. Yeah, good. Good kid stuff. manageable travel under five hours doortodoor. Yeah, great. These all look sensible. And again, it's asking me a question as a follow-up, but I can go back to my project plan over here and say, um, I think this is enough to get a short list of cities. So, let's see just as the last step for this example where it comes up with. Um, yeah. Okay, let's move straight on to just have a a short list of cities. Um, give me I don't want too many options. So maybe give me your uh top four. Maybe two kind of obvious ones and then two non-obvious ones. So we've got a bit of diversity. Let's see what it does with that. So again, getting options for for these things. And I tell you what, these two very obvious. Um okay. And okay, I think um for the non-obvious ones, let's get something kind of a little bit more exciting. Um I think these are kind of perhaps, you know, not not exciting enough for us. Um for each of the options, can you give me a um just pros and cons of each so I know what are the trade-offs and why I might choose one over the other. And again, we'll just see what the output is from this and then we'll we'll kind of finish there. So, I've given it a little bit more feedback. I kind of pushed it to get get pros and cons. It's sticking with Paris and Amsterdam. That's fine. More exciting. Copenhagen. Fourth option. Valencia much more exciting. Well, maybe than Le and Straber. Depends on your options, I guess. No offense to people less book. Okay, I'm going to stop there. Um hopefully that was helpful. Um super happy to answer any more questions that you've got. Um hopefully that was sort of like practical enough as well. If there was anything there was a little bit abstract or you didn't really kind of like resonate with you then then please do uh tell me in the chat and I'll try and make it come alive a bit more. Can I demo using the canvas? I certainly can. So if we go back to that uh conversation here then again okay these look like great options. Can you stick this in a canvas and along with the project plan um just so that we've got a kind of running uh record of like what are the steps we've completed and what are the steps we still need to go through. So you can see there we just asked it to go in the canvas. I I am using the paid version of chatgbt is the other thing. Um I'm afraid I haven't done the kind of light for light comparison to see what is um included or not included. Again I think a lot of these principles are kind of fairly general principles. Right now we've got that we can edit it and you'll see we'll open up this side pane. So these are the project plan. Okay. So here I could just give it a comment. Say um so let's select all this. Ah usually I can just comment. Can I come? There we go. If can I do that by voice? No. If the stage is complete then uh don't show the breakout. Okay. And also, you know, I I never worry about typos with LLMs because they always kind of figure out what I'm saying. So, okay, great. So, we just deleted that and you can see it's just it's just edited that part of the document. It hasn't hasn't changed anything else.